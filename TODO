TODO:

(GNU) parallel
- We may want to use the following options: 
    --eta and/or --progress: could be useful for setting up a dashboard.
    --joblog: also for dashboard.
    --load: simplifies the CPU usage checking task.
    --nonall: might speed up manual resource checking on multiple machines.
    --nice: to be nice to datalab :).
    -J: keep common configurations in profiles.
    --retries: adjust number of times to retry a failed job.
    --noswap: seems like a generally good idea, but may not "kick in" until 
      it's too late.
    --use-cpus-instead-of-cores: not sure if we need this, but it's 
      potentially relevant.

Concurrent pipeline usage
- How do we both work on a competition at the same time? Do we each have 
  separate copies of all the data, or do we just link to a shared 
  directory?
    -- One option: have the (linked) shared directory defined in the config file.

Ensemble selection
- Compute the best ensemble of methods using a held-out ensemble calibration dataset.
- Pipeline split will need to generate the held-out dataset(s).
- We need "methods" for computing the ensemble prediction (e.g. grid search, lasso, etc) 
  that take individual method predictions as input and try to predict the actual response 
  on the ensemble calibration data.
    - It may be useful to use "soft" predictions from other methods as input here. This 
      could be another use case for multiple columns in prediction files.

Unit testing

CLI for editing config.json
- Add "get" and "in" commands.
- Add some error checking and write stuff to stderr.
