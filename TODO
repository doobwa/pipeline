TODO:

Most important:
- Change write to file to be a named pipe
- Decide on how to handle method args in config.json
- Allow pipeline stage to only stage chosen methods/datasets

pipeline push
- Allow some commands to be executed serially.
- remote datalab: check ram usage
- Figure out how to check usage for multiple machines faster.

pipeline split
- Save each feature file 

pipeline compute feature x
- recompute feature x for the current splits

pipeline stage
- figure out how to send a list of features to a given method

kv
- Rewrite / nix this in favor a JSON solution.
- Add "get" and "in" commands.
- Add some error checking and write stuff to stderr.

(GNU) parallel
- We may want to use the following options: 
    --eta and/or --progress: could be useful for setting up a dashboard.
    --joblog: also for dashboard.
    --load: simplifies the CPU usage checking task.
    --nonall: might speed up manual resource checking on multiple machines.
    --nice: to be nice to datalab :).
    -J: keep common configurations in profiles.
    --retries: adjust number of times to retry a failed job.
    --noswap: seems like a generally good idea, but may not "kick in" until 
      it's too late.
    --use-cpus-instead-of-cores: not sure if we need this, but it's 
      potentially relevant.

Concurrent pipeline usage
- How do we both work on a competition at the same time? Do we each have 
  separate copies of all the data, or do we just link to a shared 
  directory?
    -- One option: have the (linked) shared directory defined in the config file.

Ensemble selection
- Compute the best ensemble of methods using a held-out ensemble calibration dataset.
- Pipeline split will need to generate the held-out dataset(s).
- We need "methods" for computing the ensemble prediction (e.g. grid search, lasso, etc) 
  that take individual method predictions as input and try to predict the actual response 
  on the ensemble calibration data.
    - It may be useful to use "soft" predictions from other methods as input here. This 
      could be another use case for multiple columns in prediction files.

Unit testing of the above functionality
